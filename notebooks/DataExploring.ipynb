{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2f56187",
   "metadata": {},
   "source": [
    "# Bird Audio Clips - First Pass Data Exploration\n",
    "\n",
    "**Project:** Zoo Congo Exhibit Bird Acoustics  \n",
    "**Data Source:** `data/fl_gaia_zoo_congo_15aug25_data/`  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1080f52e",
   "metadata": {},
   "source": [
    "## 1. Setup Environment and Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "id": "0c66c38e",
   "metadata": {},
   "source": [
    "# Standard data manipulation and analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Optional: Audio analysis (will check availability)\n",
    "try:\n",
    "    import librosa\n",
    "    import librosa.display\n",
    "    AUDIO_AVAILABLE = True\n",
    "    print(\"✓ Audio libraries (librosa) available\")\n",
    "except ImportError:\n",
    "    AUDIO_AVAILABLE = False\n",
    "    print(\"⚠ Audio libraries not available - install with: pip install librosa\")\n",
    "\n",
    "# Set visualization style\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "# Define base paths\n",
    "BASE_DIR = Path(r\"C:\\Users\\czbn2\\Documents\\Project_G18\")\n",
    "DATA_DIR = BASE_DIR / \"data\" / \"fl_gaia_zoo_congo_15aug25_data/fl_gaia_zoo_congo_15aug25_data\"\n",
    "METADATA_FILE = DATA_DIR / \"fl_gaia_zoo_congo_15aug25_data_metadata_with_perch.xlsx\"\n",
    "\n",
    "print(f\"\\nBase directory: {BASE_DIR}\")\n",
    "print(f\"Data directory: {DATA_DIR}\")\n",
    "print(f\"Metadata file: {METADATA_FILE}\")\n",
    "print(f\"\\nData directory exists: {DATA_DIR.exists()}\")\n",
    "print(f\"Metadata file exists: {METADATA_FILE.exists()}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "dbfabbab",
   "metadata": {},
   "source": [
    "## 2. Load and Inspect Metadata"
   ]
  },
  {
   "cell_type": "code",
   "id": "d1387246",
   "metadata": {},
   "source": [
    "# Load the metadata Excel file\n",
    "print(\"Loading metadata...\")\n",
    "metadata_df = pd.read_excel(METADATA_FILE)\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"METADATA OVERVIEW\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Total rows: {len(metadata_df):,}\")\n",
    "print(f\"Total columns: {len(metadata_df.columns)}\")\n",
    "print(f\"\\nDataFrame shape: {metadata_df.shape}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "9be2a19e",
   "metadata": {},
   "source": [
    "# Display column information\n",
    "print(\"\\nColumn Information:\")\n",
    "print(\"-\" * 60)\n",
    "metadata_info = pd.DataFrame({\n",
    "    'Column': metadata_df.columns,\n",
    "    'Type': metadata_df.dtypes.values,\n",
    "    'Non-Null': metadata_df.count().values,\n",
    "    'Null Count': metadata_df.isnull().sum().values\n",
    "})\n",
    "print(metadata_info.to_string(index=False))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "336e40b0",
   "metadata": {},
   "source": [
    "# Display first few rows\n",
    "print(\"\\nFirst 5 rows of metadata:\")\n",
    "print(\"=\" * 80)\n",
    "metadata_df.head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "1c21bfd2",
   "metadata": {},
   "source": [
    "# Display last few rows to see range\n",
    "print(\"\\nLast 5 rows of metadata:\")\n",
    "print(\"=\" * 80)\n",
    "metadata_df.tail()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "e4855179",
   "metadata": {},
   "source": [
    "## 3. Group Data by Species\n",
    "\n",
    "Let's identify the species column and analyze the distribution of clips across species."
   ]
  },
  {
   "cell_type": "code",
   "id": "3dbca8b6",
   "metadata": {},
   "source": [
    "species_col = 'scientific_name' if 'scientific_name' in metadata_df.columns else None\n",
    "\n",
    "if species_col:\n",
    "    print(f\"Using '{species_col}' as species identifier\\n\")\n",
    "    \n",
    "    species_summary = metadata_df[species_col].value_counts().reset_index()\n",
    "    species_summary.columns = ['Species', 'Clip Count']\n",
    "    species_summary['Percentage'] = (species_summary['Clip Count'] / len(metadata_df) * 100).round(2)\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(\"CLIPS PER SPECIES\")\n",
    "    print(\"=\"*60)\n",
    "    print(species_summary.to_string(index=False))\n",
    "    print(f\"\\nTotal unique species: {len(species_summary)}\")\n",
    "else:\n",
    "    print(\"⚠ Could not automatically identify species column. Please specify manually.\")\n",
    "    species_summary = None"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "33d7f255",
   "metadata": {},
   "source": [
    "## 4. Scan Audio File Structure\n",
    "\n",
    "Let's discover all audio files in folders 1-428 and understand the file organization."
   ]
  },
  {
   "cell_type": "code",
   "id": "99322ff7",
   "metadata": {},
   "source": [
    "# Scan for audio files\n",
    "print(\"Scanning audio folders...\")\n",
    "print(\"This may take a moment for large datasets...\\n\")\n",
    "\n",
    "audio_extensions = {'.wav', '.mp3', '.flac', '.ogg', '.m4a'}\n",
    "audio_files = []\n",
    "\n",
    "# Scan numbered folders 1-428\n",
    "for folder_num in range(1, 429):\n",
    "    folder_path = DATA_DIR / str(folder_num)\n",
    "    if folder_path.exists():\n",
    "        # Find all audio files in this folder\n",
    "        for file_path in folder_path.rglob('*'):\n",
    "            if file_path.is_file() and file_path.suffix.lower() in audio_extensions:\n",
    "                audio_files.append({\n",
    "                    'full_path': str(file_path),\n",
    "                    'folder_id': folder_num,\n",
    "                    'filename': file_path.name,\n",
    "                    'stem': file_path.stem,\n",
    "                    'extension': file_path.suffix,\n",
    "                    'relative_path': str(file_path.relative_to(DATA_DIR))\n",
    "                })\n",
    "\n",
    "audio_df = pd.DataFrame(audio_files)\n",
    "\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"AUDIO FILES DISCOVERED\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Total audio files found: {len(audio_df):,}\")\n",
    "\n",
    "if len(audio_df) > 0:\n",
    "    print(f\"\\nFolders with audio: {audio_df['folder_id'].nunique()}\")\n",
    "    print(f\"File extensions: {audio_df['extension'].value_counts().to_dict()}\")\n",
    "    print(f\"\\nFirst few audio files:\")\n",
    "    display(audio_df.head(10))\n",
    "else:\n",
    "    print(\"\\n⚠ No audio files found. Check the folder structure.\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "864c75b9",
   "metadata": {},
   "source": [
    "# Analyze folder distribution\n",
    "if len(audio_df) > 0:\n",
    "    folder_counts = audio_df['folder_id'].value_counts().sort_index()\n",
    "    \n",
    "    print(f\"\\nAudio files per folder - Summary Statistics:\")\n",
    "    print(f\"  Mean: {folder_counts.mean():.1f}\")\n",
    "    print(f\"  Median: {folder_counts.median():.1f}\")\n",
    "    print(f\"  Min: {folder_counts.min()}\")\n",
    "    print(f\"  Max: {folder_counts.max()}\")\n",
    "    \n",
    "    print(f\"\\nTop 10 folders by file count:\")\n",
    "    print(folder_counts.head(10))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "f4e1b77c",
   "metadata": {},
   "source": [
    "## 5. Link Metadata to Audio Files\n",
    "\n",
    "The metadata contains a 'filename' column with relative paths (from the data directory root) that correspond to the audio .wav files. Let's verify this linkage and construct absolute paths.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "731239fc",
   "metadata": {},
   "source": [
    "# Check if 'filename' column exists in metadata\n",
    "if 'filename' in metadata_df.columns:\n",
    "    print(\"✓ 'filename' column found in metadata\\n\")\n",
    "    \n",
    "    # The metadata 'filename' column contains relative paths from DATA_DIR parent\n",
    "    # e.g., \"fl_gaia_zoo_congo_15aug25_data/0/er_file_2025_08_08_11_00_02.500000.wav\"\n",
    "    # We need to construct full absolute paths\n",
    "    \n",
    "    # Convert metadata filename paths to absolute paths\n",
    "    metadata_df['audio_path'] = metadata_df['filename'].apply(\n",
    "        lambda x: str(BASE_DIR / \"data\" / x) if pd.notna(x) else None\n",
    "    )\n",
    "    \n",
    "    # Check which files actually exist\n",
    "    metadata_df['has_audio'] = metadata_df['audio_path'].apply(\n",
    "        lambda x: Path(x).exists() if x is not None else False\n",
    "    )\n",
    "    \n",
    "    # Statistics\n",
    "    matched_count = metadata_df['has_audio'].sum()\n",
    "    match_rate = (matched_count / len(metadata_df) * 100)\n",
    "    \n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"METADATA-AUDIO LINKAGE\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Total metadata rows: {len(metadata_df):,}\")\n",
    "    print(f\"Metadata rows with audio: {matched_count:,}\")\n",
    "    print(f\"Match rate: {match_rate:.2f}%\")\n",
    "    print(f\"\\nUnmatched metadata rows: {len(metadata_df) - matched_count:,}\")\n",
    "    \n",
    "    # Show examples of matched and unmatched\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"MATCHED EXAMPLES (first 5):\")\n",
    "    print(f\"{'='*60}\")\n",
    "    matched_samples = metadata_df[metadata_df['has_audio']].head()\n",
    "    for idx, row in matched_samples.iterrows():\n",
    "        print(f\"  {row['filename']}\")\n",
    "        print(f\"    -> {row['audio_path']}\")\n",
    "    \n",
    "    if (len(metadata_df) - matched_count) > 0:\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"UNMATCHED EXAMPLES (first 5):\")\n",
    "        print(f\"{'='*60}\")\n",
    "        unmatched_samples = metadata_df[~metadata_df['has_audio']].head()\n",
    "        for idx, row in unmatched_samples.iterrows():\n",
    "            print(f\"  {row['filename']}\")\n",
    "            if pd.notna(row['audio_path']):\n",
    "                print(f\"    Expected at: {row['audio_path']}\")\n",
    "else:\n",
    "    print(\"⚠ 'filename' column not found in metadata\")\n",
    "    print(f\"Available columns: {list(metadata_df.columns)}\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "2f3e91de",
   "metadata": {},
   "source": [
    "## 6. Preliminary Data Analysis\n",
    "\n",
    "Now that we've linked metadata to audio files, let's explore the key columns and their relationships."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7cceb74",
   "metadata": {},
   "source": [
    "### 6.1 Species Detection Analysis\n",
    "\n",
    "Analyze the PERCH model predictions: scientific_name, code (species code), and confidence scores."
   ]
  },
  {
   "cell_type": "code",
   "id": "4c63ea07",
   "metadata": {},
   "source": [
    "# Analyze species detections and confidence scores\n",
    "print(\"=\"*70)\n",
    "print(\"SPECIES DETECTION SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Basic stats on detections\n",
    "print(f\"\\nTotal clips analyzed: {len(metadata_df):,}\")\n",
    "print(f\"Clips with species detected: {metadata_df['scientific_name'].notna().sum():,}\")\n",
    "print(f\"Clips without detection: {metadata_df['scientific_name'].isna().sum():,}\")\n",
    "\n",
    "# Score distribution\n",
    "if 'score' in metadata_df.columns:\n",
    "    print(f\"\\nConfidence Score Statistics:\")\n",
    "    print(f\"  Mean: {metadata_df['score'].mean():.3f}\")\n",
    "    print(f\"  Median: {metadata_df['score'].median():.3f}\")\n",
    "    print(f\"  Min: {metadata_df['score'].min():.3f}\")\n",
    "    print(f\"  Max: {metadata_df['score'].max():.3f}\")\n",
    "    print(f\"  Std Dev: {metadata_df['score'].std():.3f}\")\n",
    "    \n",
    "    # Score distribution by quartile\n",
    "    print(f\"\\nScore Quartiles:\")\n",
    "    for q in [0.25, 0.50, 0.75, 0.90, 0.95, 0.99]:\n",
    "        val = metadata_df['score'].quantile(q)\n",
    "        print(f\"  {int(q*100)}th percentile: {val:.3f}\")\n",
    "\n",
    "# Top species by detection count\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"TOP 10 DETECTED SPECIES (by count)\")\n",
    "print(f\"{'='*70}\")\n",
    "top_species = metadata_df['scientific_name'].value_counts().head(10).reset_index()\n",
    "top_species.columns = ['Species', 'Count']\n",
    "top_species['Percentage'] = (top_species['Count'] / len(metadata_df) * 100).round(2)\n",
    "print(top_species.to_string(index=False))\n",
    "\n",
    "# Average confidence score by species\n",
    "if 'score' in metadata_df.columns:\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"AVERAGE CONFIDENCE SCORE BY SPECIES (Top 10 by count)\")\n",
    "    print(f\"{'='*70}\")\n",
    "    species_scores = metadata_df.groupby('scientific_name')['score'].agg(['mean', 'count', 'std']).sort_values('count', ascending=False).head(10)\n",
    "    species_scores.columns = ['Avg Score', 'Count', 'Std Dev']\n",
    "    species_scores['Avg Score'] = species_scores['Avg Score'].round(3)\n",
    "    species_scores['Std Dev'] = species_scores['Std Dev'].round(3)\n",
    "    print(species_scores)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "339d43ef",
   "metadata": {},
   "source": [
    "# Visualize species distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Bar chart of top species\n",
    "top_n = 15\n",
    "top_species_plot = metadata_df['scientific_name'].value_counts().head(top_n)\n",
    "axes[0].barh(range(len(top_species_plot)), top_species_plot.values, color='steelblue')\n",
    "axes[0].set_yticks(range(len(top_species_plot)))\n",
    "axes[0].set_yticklabels(top_species_plot.index, fontsize=9)\n",
    "axes[0].set_xlabel('Number of Clips', fontsize=11)\n",
    "axes[0].set_title(f'Top {top_n} Species by Detection Count', fontsize=12, fontweight='bold')\n",
    "axes[0].invert_yaxis()\n",
    "axes[0].grid(axis='x', alpha=0.3)\n",
    "\n",
    "# Add count labels\n",
    "for i, v in enumerate(top_species_plot.values):\n",
    "    axes[0].text(v + max(top_species_plot.values)*0.01, i, f'{v:,}', va='center', fontsize=9)\n",
    "\n",
    "# Score distribution histogram\n",
    "if 'score' in metadata_df.columns:\n",
    "    axes[1].hist(metadata_df['score'].dropna(), bins=50, color='coral', edgecolor='black', alpha=0.7)\n",
    "    axes[1].axvline(metadata_df['score'].mean(), color='red', linestyle='--', linewidth=2, label=f'Mean: {metadata_df[\"score\"].mean():.3f}')\n",
    "    axes[1].axvline(metadata_df['score'].median(), color='blue', linestyle='--', linewidth=2, label=f'Median: {metadata_df[\"score\"].median():.3f}')\n",
    "    axes[1].set_xlabel('Confidence Score', fontsize=11)\n",
    "    axes[1].set_ylabel('Frequency', fontsize=11)\n",
    "    axes[1].set_title('Distribution of Confidence Scores', fontsize=12, fontweight='bold')\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "b7f518f4",
   "metadata": {},
   "source": [
    "### 6.2 Temporal Analysis\n",
    "\n",
    "Explore temporal patterns in the recordings using the datetime column."
   ]
  },
  {
   "cell_type": "code",
   "id": "1bdbf4be",
   "metadata": {},
   "source": [
    "# Convert datetime column to datetime type if not already\n",
    "if 'datetime' in metadata_df.columns:\n",
    "    metadata_df['datetime_parsed'] = pd.to_datetime(metadata_df['datetime'], errors='coerce')\n",
    "    \n",
    "    # Extract time components\n",
    "    metadata_df['date'] = metadata_df['datetime_parsed'].dt.date\n",
    "    metadata_df['hour'] = metadata_df['datetime_parsed'].dt.hour\n",
    "    metadata_df['day_of_week'] = metadata_df['datetime_parsed'].dt.day_name()\n",
    "    metadata_df['month'] = metadata_df['datetime_parsed'].dt.month\n",
    "    metadata_df['month_name'] = metadata_df['datetime_parsed'].dt.month_name()\n",
    "    \n",
    "    print(\"=\"*70)\n",
    "    print(\"TEMPORAL COVERAGE\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"Date range: {metadata_df['datetime_parsed'].min()} to {metadata_df['datetime_parsed'].max()}\")\n",
    "    print(f\"Total days covered: {metadata_df['date'].nunique():,}\")\n",
    "    print(f\"Total clips: {len(metadata_df):,}\")\n",
    "    print(f\"Average clips per day: {len(metadata_df) / metadata_df['date'].nunique():.1f}\")\n",
    "    \n",
    "    # Hourly distribution\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"RECORDINGS BY HOUR OF DAY\")\n",
    "    print(f\"{'='*70}\")\n",
    "    hourly_counts = metadata_df['hour'].value_counts().sort_index()\n",
    "    for hour, count in hourly_counts.items():\n",
    "        bar_length = int(count / hourly_counts.max() * 40)\n",
    "        bar = '█' * bar_length\n",
    "        print(f\"{hour:02d}:00  {bar} {count:,}\")\n",
    "    \n",
    "    # Daily distribution\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"RECORDINGS BY DAY OF WEEK\")\n",
    "    print(f\"{'='*70}\")\n",
    "    day_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "    day_counts = metadata_df['day_of_week'].value_counts().reindex(day_order, fill_value=0)\n",
    "    for day, count in day_counts.items():\n",
    "        bar_length = int(count / day_counts.max() * 40)\n",
    "        bar = '█' * bar_length\n",
    "        print(f\"{day:10s}  {bar} {count:,}\")\n",
    "else:\n",
    "    print(\"⚠ 'datetime' column not found in metadata\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "57ecce93",
   "metadata": {},
   "source": [
    "# Visualize temporal patterns\n",
    "if 'datetime_parsed' in metadata_df.columns:\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 10))\n",
    "    \n",
    "    # Hour of day distribution\n",
    "    hourly_counts = metadata_df['hour'].value_counts().sort_index()\n",
    "    axes[0, 0].bar(hourly_counts.index, hourly_counts.values, color='skyblue', edgecolor='black')\n",
    "    axes[0, 0].set_xlabel('Hour of Day', fontsize=11)\n",
    "    axes[0, 0].set_ylabel('Number of Recordings', fontsize=11)\n",
    "    axes[0, 0].set_title('Recordings by Hour of Day', fontsize=12, fontweight='bold')\n",
    "    axes[0, 0].set_xticks(range(0, 24, 2))\n",
    "    axes[0, 0].grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # Day of week distribution\n",
    "    day_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "    day_counts = metadata_df['day_of_week'].value_counts().reindex(day_order, fill_value=0)\n",
    "    axes[0, 1].bar(range(len(day_counts)), day_counts.values, color='lightcoral', edgecolor='black')\n",
    "    axes[0, 1].set_xticks(range(len(day_counts)))\n",
    "    axes[0, 1].set_xticklabels([d[:3] for d in day_order], fontsize=10)\n",
    "    axes[0, 1].set_xlabel('Day of Week', fontsize=11)\n",
    "    axes[0, 1].set_ylabel('Number of Recordings', fontsize=11)\n",
    "    axes[0, 1].set_title('Recordings by Day of Week', fontsize=12, fontweight='bold')\n",
    "    axes[0, 1].grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # Daily timeline\n",
    "    daily_counts = metadata_df.groupby('date').size()\n",
    "    axes[1, 0].plot(daily_counts.index, daily_counts.values, marker='o', linewidth=1, markersize=3, color='green')\n",
    "    axes[1, 0].set_xlabel('Date', fontsize=11)\n",
    "    axes[1, 0].set_ylabel('Number of Recordings', fontsize=11)\n",
    "    axes[1, 0].set_title('Recordings Over Time (Daily)', fontsize=12, fontweight='bold')\n",
    "    axes[1, 0].tick_params(axis='x', rotation=45)\n",
    "    axes[1, 0].grid(alpha=0.3)\n",
    "    \n",
    "    # Heatmap: Hour vs Day of Week\n",
    "    pivot_data = metadata_df.groupby(['day_of_week', 'hour']).size().reset_index(name='count')\n",
    "    pivot_table = pivot_data.pivot(index='day_of_week', columns='hour', values='count').fillna(0)\n",
    "    pivot_table = pivot_table.reindex(day_order)\n",
    "    \n",
    "    im = axes[1, 1].imshow(pivot_table.values, cmap='YlOrRd', aspect='auto')\n",
    "    axes[1, 1].set_xticks(range(0, 24, 2))\n",
    "    axes[1, 1].set_xticklabels(range(0, 24, 2))\n",
    "    axes[1, 1].set_yticks(range(len(day_order)))\n",
    "    axes[1, 1].set_yticklabels([d[:3] for d in day_order])\n",
    "    axes[1, 1].set_xlabel('Hour of Day', fontsize=11)\n",
    "    axes[1, 1].set_ylabel('Day of Week', fontsize=11)\n",
    "    axes[1, 1].set_title('Recording Intensity Heatmap', fontsize=12, fontweight='bold')\n",
    "    \n",
    "    # Add colorbar\n",
    "    cbar = plt.colorbar(im, ax=axes[1, 1])\n",
    "    cbar.set_label('Number of Recordings', fontsize=10)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "c7815e4e",
   "metadata": {},
   "source": [
    "### 6.3 Weather Conditions Analysis\n",
    "\n",
    "Explore how weather conditions relate to bird activity and detection rates."
   ]
  },
  {
   "cell_type": "code",
   "id": "2ad8cc3b",
   "metadata": {},
   "source": [
    "# Analyze weather variables\n",
    "weather_cols = ['tempAve', 'humidityAvg', 'precipRate', 'windspeedAvg', \n",
    "                'pressureMax', 'dewptAvg', 'solarRadiationHigh', 'uvHigh']\n",
    "\n",
    "# Check which weather columns exist\n",
    "available_weather = [col for col in weather_cols if col in metadata_df.columns]\n",
    "\n",
    "if available_weather:\n",
    "    print(\"=\"*70)\n",
    "    print(\"WEATHER CONDITIONS SUMMARY\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    for col in available_weather:\n",
    "        data = metadata_df[col].dropna()\n",
    "        if len(data) > 0:\n",
    "            print(f\"\\n{col}:\")\n",
    "            print(f\"  Mean: {data.mean():.2f}\")\n",
    "            print(f\"  Median: {data.median():.2f}\")\n",
    "            print(f\"  Min: {data.min():.2f}\")\n",
    "            print(f\"  Max: {data.max():.2f}\")\n",
    "            print(f\"  Std Dev: {data.std():.2f}\")\n",
    "            print(f\"  Missing: {metadata_df[col].isna().sum():,} ({metadata_df[col].isna().sum()/len(metadata_df)*100:.1f}%)\")\n",
    "else:\n",
    "    print(\"⚠ No weather columns found in metadata\")\n",
    "\n",
    "# Correlation between weather and detection confidence\n",
    "if available_weather and 'score' in metadata_df.columns:\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"CORRELATION: Weather vs. Detection Confidence Score\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    correlations = []\n",
    "    for col in available_weather:\n",
    "        if metadata_df[col].notna().sum() > 0:\n",
    "            corr = metadata_df[[col, 'score']].corr().iloc[0, 1]\n",
    "            correlations.append({'Weather Variable': col, 'Correlation': corr})\n",
    "    \n",
    "    if correlations:\n",
    "        corr_df = pd.DataFrame(correlations).sort_values('Correlation', ascending=False)\n",
    "        corr_df['Correlation'] = corr_df['Correlation'].round(3)\n",
    "        print(corr_df.to_string(index=False))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "5ee21401",
   "metadata": {},
   "source": [
    "# Visualize weather conditions\n",
    "if available_weather:\n",
    "    # Select up to 6 key weather variables for visualization\n",
    "    plot_weather = available_weather[:6]\n",
    "    n_plots = len(plot_weather)\n",
    "    n_cols = 3\n",
    "    n_rows = (n_plots + n_cols - 1) // n_cols\n",
    "    \n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(16, n_rows * 4))\n",
    "    axes = axes.flatten() if n_plots > 1 else [axes]\n",
    "    \n",
    "    for idx, col in enumerate(plot_weather):\n",
    "        data = metadata_df[col].dropna()\n",
    "        if len(data) > 0:\n",
    "            axes[idx].hist(data, bins=50, color='teal', alpha=0.7, edgecolor='black')\n",
    "            axes[idx].axvline(data.mean(), color='red', linestyle='--', linewidth=2, \n",
    "                            label=f'Mean: {data.mean():.2f}')\n",
    "            axes[idx].axvline(data.median(), color='blue', linestyle='--', linewidth=2,\n",
    "                            label=f'Median: {data.median():.2f}')\n",
    "            axes[idx].set_xlabel(col, fontsize=11)\n",
    "            axes[idx].set_ylabel('Frequency', fontsize=11)\n",
    "            axes[idx].set_title(f'Distribution of {col}', fontsize=11, fontweight='bold')\n",
    "            axes[idx].legend(fontsize=9)\n",
    "            axes[idx].grid(alpha=0.3)\n",
    "    \n",
    "    # Hide empty subplots\n",
    "    for idx in range(n_plots, len(axes)):\n",
    "        axes[idx].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "18d9ff42",
   "metadata": {},
   "source": [
    "### 6.4 Species Activity Patterns\n",
    "\n",
    "Analyze when different species are most active throughout the day."
   ]
  },
  {
   "cell_type": "code",
   "id": "0379722e",
   "metadata": {},
   "source": [
    "# Analyze species activity by time of day\n",
    "if 'hour' in metadata_df.columns and 'scientific_name' in metadata_df.columns:\n",
    "    \n",
    "    # Get top 5 most common species\n",
    "    top_5_species = metadata_df['scientific_name'].value_counts().head(5).index.tolist()\n",
    "    \n",
    "    print(\"=\"*70)\n",
    "    print(\"SPECIES ACTIVITY BY HOUR (Top 5 Species)\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Create pivot table: species x hour\n",
    "    species_hour = metadata_df[metadata_df['scientific_name'].isin(top_5_species)].groupby(\n",
    "        ['scientific_name', 'hour']).size().reset_index(name='count')\n",
    "    \n",
    "    for species in top_5_species:\n",
    "        print(f\"\\n{species}:\")\n",
    "        species_data = species_hour[species_hour['scientific_name'] == species]\n",
    "        total_detections = species_data['count'].sum()\n",
    "        \n",
    "        for _, row in species_data.sort_values('hour').iterrows():\n",
    "            hour = int(row['hour'])\n",
    "            count = int(row['count'])\n",
    "            pct = (count / total_detections * 100)\n",
    "            bar_length = int(pct / 2)  # Scale to fit\n",
    "            bar = '█' * bar_length\n",
    "            print(f\"  {hour:02d}:00  {bar} {count:4d} ({pct:5.1f}%)\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "1588cca6",
   "metadata": {},
   "source": [
    "# Visualize species activity patterns\n",
    "if 'hour' in metadata_df.columns and 'scientific_name' in metadata_df.columns:\n",
    "    \n",
    "    top_5_species = metadata_df['scientific_name'].value_counts().head(5).index.tolist()\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 1, figsize=(16, 10))\n",
    "    \n",
    "    # Line plot: Activity by hour for top species\n",
    "    for species in top_5_species:\n",
    "        species_hourly = metadata_df[metadata_df['scientific_name'] == species].groupby('hour').size()\n",
    "        axes[0].plot(species_hourly.index, species_hourly.values, marker='o', linewidth=2, \n",
    "                    label=species, markersize=6)\n",
    "    \n",
    "    axes[0].set_xlabel('Hour of Day', fontsize=11)\n",
    "    axes[0].set_ylabel('Number of Detections', fontsize=11)\n",
    "    axes[0].set_title('Species Activity Throughout the Day (Top 5 Species)', fontsize=12, fontweight='bold')\n",
    "    axes[0].legend(fontsize=9, loc='best')\n",
    "    axes[0].set_xticks(range(0, 24))\n",
    "    axes[0].grid(alpha=0.3)\n",
    "    \n",
    "    # Heatmap: Species vs Hour\n",
    "    pivot_data = metadata_df[metadata_df['scientific_name'].isin(top_5_species)].groupby(\n",
    "        ['scientific_name', 'hour']).size().reset_index(name='count')\n",
    "    pivot_table = pivot_data.pivot(index='scientific_name', columns='hour', values='count').fillna(0)\n",
    "    \n",
    "    im = axes[1].imshow(pivot_table.values, cmap='YlGnBu', aspect='auto')\n",
    "    axes[1].set_xticks(range(24))\n",
    "    axes[1].set_xticklabels(range(24))\n",
    "    axes[1].set_yticks(range(len(pivot_table.index)))\n",
    "    axes[1].set_yticklabels(pivot_table.index, fontsize=9)\n",
    "    axes[1].set_xlabel('Hour of Day', fontsize=11)\n",
    "    axes[1].set_ylabel('Species', fontsize=11)\n",
    "    axes[1].set_title('Species Detection Intensity Heatmap', fontsize=12, fontweight='bold')\n",
    "    \n",
    "    # Add colorbar\n",
    "    cbar = plt.colorbar(im, ax=axes[1])\n",
    "    cbar.set_label('Number of Detections', fontsize=10)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Weather Analysis - Data",
   "id": "ebfd13ddd235b6fd"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Weather Related Analysis",
   "id": "2474b553e46caec4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import seaborn as sns\n",
    "# Top 10 most common scientific names\n",
    "top10 = metadata_df['scientific_name'].value_counts().nlargest(10).index\n",
    "data_top10 = metadata_df[metadata_df['scientific_name'].isin(top10)]\n",
    "metadata_df.head()# frequency of top 10 species\n",
    "\n",
    "# Plots\n",
    "def createBoxplotsOnData(data_frame,x,y,title,ylabel,filename):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.boxplot(\n",
    "        x=x,\n",
    "        y=y,\n",
    "        data=data_frame,\n",
    "        palette='coolwarm',\n",
    "        showmeans=True,\n",
    "        meanprops={\"marker\": \"o\", \"markerfacecolor\": \"black\", \"markeredgecolor\": \"black\"}\n",
    "    )\n",
    "\n",
    "    plt.title(title)\n",
    "    plt.xlabel(x)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{BASE_DIR}/Plots/{filename}\", dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "def createDistPlotsOnData(data_frame,datax,y,title,ylabel,filename):\n",
    "    counts = data_frame[datax].value_counts().to_dict() #data occurance (for labels)\n",
    "    data_top10['scientific_label'] = data_top10[datax].apply(\n",
    "    lambda x: f\"{x}\\n(n={counts[x]})\"\n",
    "    )\n",
    "\n",
    "    # --- Faceted density plots with count in labels ---\n",
    "    g = sns.FacetGrid(\n",
    "        data_frame,\n",
    "        col='scientific_label',\n",
    "        col_wrap=5,\n",
    "        height=3.5,\n",
    "        sharex=True,\n",
    "        sharey=True\n",
    "    )\n",
    "    g.map(sns.kdeplot, y, fill=True, color='skyblue')\n",
    "    g.fig.suptitle(title, y=1.02)\n",
    "    g.savefig(f\"{BASE_DIR}/Plots/{filename}\", dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "#Metric Functions\n",
    "\n",
    "def generate_timespan_dataframe(data_frame, datetime_start, datetime_end):\n",
    "    #Ensure datetime feature is in datetime format\n",
    "    df = data_frame.copy()\n",
    "    df[\"datetime_parsed\"] = pd.to_datetime(df[\"datetime_parsed\"], errors=\"coerce\")\n",
    "\n",
    "    #Filter between start and end ranges\n",
    "    mask = (df[\"datetime\"] >= datetime_start) & (df[\"datetime\"] <= datetime_end)\n",
    "    new_df = df.loc[mask]\n",
    "    return new_df\n",
    "\n",
    "\n",
    "\n",
    "data_top10.head()\n",
    "#datasettime = generate_timespan_dataframe(data_top10,\"2025-08-08\", \"2025-08-09\");"
   ],
   "id": "5a7c37ecb04a0b0a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### EDA",
   "id": "b6fd182eb7950382"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "data_top10.info()",
   "id": "97a0f3ab7e275712",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "weather_cols = [\n",
    "    \"precipRate\", \"pressureMax\", \"dewptAvg\", \"windgustHigh\",\n",
    "    \"windspeedAvg\", \"tempAve\", \"humidityAvg\", \"winddirAvg\",\n",
    "    \"uvHigh\", \"solarRadiationHigh\"\n",
    "]\n",
    "\n",
    "#Summary weather stats\n",
    "df_weather = data_top10[weather_cols]\n",
    "print(df_weather.describe())\n",
    "print(\"\")\n",
    "#Detect missing values\n",
    "print(\"Amount of Missing data per feature\")\n",
    "print(df_weather.isna().sum())\n",
    "print(\"\")\n",
    "print(\"Unique values per column\")\n",
    "print(df_weather.nunique())\n",
    "print(\"\")\n",
    "print(\"Earsliest and latest date in dataset\")\n",
    "print(data_top10[\"datetime\"].min())\n",
    "print(data_top10[\"datetime\"].max())"
   ],
   "id": "ee12f60329e39f69",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### What can we see from those metrics?\n",
    "| Feature              | Mean    | Std    | Min     | 25%     | 50%     | 75%     | Max     | Unique Values | Missing Values |\n",
    "| -------------------- | ------- | ------ | ------- | ------- | ------- | ------- | ------- | ------------- | -------------- |\n",
    "| `precipRate`         | 0.00    | 0.00   | 0.00    | 0.00    | 0.00    | 0.00    | 0.00    | 1             | 0              |\n",
    "| `pressureMax`        | 1027.54 | 4.45   | 1019.74 | 1023.94 | 1026.62 | 1032.34 | 1035.32 | 155           | 0              |\n",
    "| `dewptAvg`           | 14.87   | 2.95   | 10.10   | 12.10   | 14.20   | 17.70   | 21.70   | 115           | 0              |\n",
    "| `windgustHigh`       | 2.54    | 2.92   | 0.00    | 0.00    | 1.80    | 3.50    | 16.60   | 10            | 0              |\n",
    "| `windspeedAvg`       | 0.38    | 0.58   | 0.00    | 0.00    | 0.10    | 0.60    | 4.90    | 36            | 0              |\n",
    "| `tempAve`            | 22.69   | 7.85   | 11.10   | 13.80   | 23.30   | 28.30   | 38.30   | 265           | 0              |\n",
    "| `humidityAvg`        | 66.42   | 22.91  | 29.40   | 42.10   | 68.40   | 91.00   | 95.00   | 509           | 0              |\n",
    "| `winddirAvg`         | 213.53  | 45.52  | 3.00    | 203.00  | 222.00  | 242.00  | 349.00  | 216           | 0              |\n",
    "| `uvHigh`             | 1.47    | 1.88   | 0.00    | 0.00    | 0.00    | 3.00    | 6.00    | 7             | 0              |\n",
    "| `solarRadiationHigh` | 183.10  | 206.99 | 0.00    | 0.00    | 90.40   | 349.70  | 713.40  | 1,020         | 0              |\n",
    "\n",
    "**Total records:** 20,896 <br>\n",
    "**Date range:** 2025-08-08 11:00:13 → 2025-08-15 07:55:02 <br>\n",
    "**Missing values:** None (0 missing in all weather features <br>\n",
    "#### Key Insights: <br>\n",
    "No missing values across any weather variables - clean dataset <br>\n",
    "**precipRate:** constant (0.0) offers no variation - candidate for exclusion. <br>\n",
    "**pressureMax, tempAve, and humidityAvg** show healthy spread - good for anomaly modeling. <br>\n",
    "**solarRadiationHigh** has the widest numeric range and high variance (day/night cycles). <br>\n",
    "High uniqueness in **humidityAvg, tempAve, and solarRadiationHigh** indicates continuous readings. <br>\n",
    "**Time coverage:** ~7 days of data (1 week window)."
   ],
   "id": "2f0d4d02596b922"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plt.figure(figsize=(14, 10))\n",
    "for i, col in enumerate(weather_cols, 1):\n",
    "    plt.subplot(4, 3, i)\n",
    "    sns.histplot(data_top10[col].dropna(), bins=30, kde=True, color=\"skyblue\")\n",
    "    plt.title(f\"{col} Distribution\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ],
   "id": "f9677684576ff171",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Distribution Insights",
   "id": "b3de10d6af2cea6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "fig, axes = plt.subplots(3, 3, figsize=(14,10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, col in enumerate(weather_cols[:9]):  # limit to first 9 for readability\n",
    "    sns.boxplot(x=data_top10[col], ax=axes[i])\n",
    "    axes[i].set_title(col)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "478c613f0b01432a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Boxplot Insights",
   "id": "5c32fa9d59b28dbc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Pearson Correlation\n",
    "plt.figure(figsize=(10,8))\n",
    "sns.heatmap(df_weather.corr(), annot=True, fmt=\".2f\", cmap=\"RdPu\")\n",
    "plt.title(\"Correlation Matrix of Weather Variables\")\n",
    "plt.show()\n",
    "\n",
    "species_weather = (\n",
    "    data_top10.groupby(\"scientific_name\")[weather_cols].mean()\n",
    ")\n",
    "sns.heatmap(species_weather.corr(), annot=True, cmap=\"RdPu\")\n",
    "plt.title(\"Correlation Between Average Weather Features (Across Species)\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "weather_feature = [\"tempAve\", \"pressureMax\", \"windgustHigh\", \"solarRadiationHigh\"]\n",
    "species_list = data_top10[\"scientific_name\"].unique()\n",
    "os.makedirs(f\"Plots\", exist_ok=True)\n",
    "for weather in weather_feature:\n",
    "    for species in species_list:\n",
    "        subset = data_top10[data_top10[\"scientific_name\"] == species]\n",
    "        plt.figure(figsize=(8,4))\n",
    "        sns.histplot(subset[weather], bins=20, kde=True, color=\"steelblue\")\n",
    "        plt.title(f\"{species} — Distribution of {weather}\")\n",
    "        plt.xlabel(f\"{weather} (°C)\")\n",
    "        plt.ylabel(\"Number of Recordings\")\n",
    "        os.makedirs(f\"Plots/{species}/weather_dist\", exist_ok=True)\n",
    "        plt.savefig(f\"Plots/{species}/weather_dist/{species}_{weather}.png\", dpi=300)\n",
    "        plt.show()\n"
   ],
   "id": "1f03010dc035baf3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Correlation Analysis\n",
    "Correlation range <-1,1>\n",
    "Negative correlation = as x feature grows the y feature decreases\n",
    "Positive correlation = both x and y features increase or decrease together\n",
    "0 = no linear correlation (can have non-linear correlation)\n",
    "### Distribution Summary\n",
    "Most Basileuterus rufifrons recordings occur in mild, calm, low-light conditions.\n",
    "less data is collected happen when weather is hot, windy, bright, or under shifting pressure,\n",
    "rather than suggesting uncommon environmental contexts or acoustic outliers I think it is more related to the time of the year the recordings were recorded in. Suggesting that it is better if we can compare seasons instead. (Ask Gaia to record more audio now during colder days?), look into daily weather dist"
   ],
   "id": "8b092433904b5932"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "species = [\"Strix aluco\"]\n",
    "subsetDay = generate_timespan_dataframe(data_top10,\"2025-08-08\", \"2025-08-09\");\n",
    "for weather in weather_feature:\n",
    "    for species in species_list:\n",
    "        subset = subsetDay[subsetDay[\"scientific_name\"] == species]\n",
    "        plt.figure(figsize=(8,4))\n",
    "        sns.histplot(subset[weather], bins=20, kde=True, color=\"steelblue\")\n",
    "        plt.title(f\"{species} — Distribution of {weather}\")\n",
    "        plt.xlabel(f\"{weather} (°C)\")\n",
    "        plt.ylabel(\"Number of Recordings\")\n",
    "        ##os.makedirs(f\"Plots/{species}/weather_dist\", exist_ok=True)\n",
    "        plt.savefig(f\"Plots/{species}/weather_dist/{species}_{weather}.png\", dpi=300)\n",
    "        plt.show()"
   ],
   "id": "3c75bbf14e96ab8f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Same day, but species are active on diffrent time of a day -> look into it",
   "id": "d3fef5889ea0bc10"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "weather_feature = [\"tempAve\", \"windgustHigh\"]\n",
    "hourly = data_top10.groupby(\"hour\")[weather_feature].mean()\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "for col in [\"tempAve\"]:\n",
    "    plt.plot(hourly.index, hourly[col], label=col)\n",
    "plt.legend()\n",
    "plt.title(\"Average Weather Variables by Hour of Day\")\n",
    "plt.xlabel(\"Hour of Day\")\n",
    "plt.ylabel(\"Mean Value\")\n",
    "plt.show()\n",
    "\n",
    "for species in data_top10[\"scientific_name\"].unique():\n",
    "    subset = data_top10[data_top10[\"scientific_name\"] == species].copy()\n",
    "\n",
    "    # Compute hourly means\n",
    "    hourly = subset.groupby(\"hour\")[weather_feature].mean().reset_index()\n",
    "\n",
    "    # --- Plot ---\n",
    "    plt.figure(figsize=(12,6))\n",
    "    for col in weather_feature:\n",
    "        plt.plot(hourly[\"hour\"], hourly[col], marker=\"o\", linewidth=1.5, label=col)\n",
    "\n",
    "    plt.title(f\"Hourly Mean Weather Conditions for {species}\")\n",
    "    plt.xlabel(\"Hour of Day\")\n",
    "    plt.ylabel(\"Mean Value\")\n",
    "    plt.legend(bbox_to_anchor=(1.05,1), loc=\"upper left\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n"
   ],
   "id": "4aecbb93c8020787",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Temporal Weather Analys",
   "id": "9d6da84be10e98e7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "WindGust diffrent scale!! look into plotting weather for all spiecies in one gpraph per weather feature",
   "id": "2c1090e99a96f4e8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for species in data_top10[\"scientific_name\"].unique():\n",
    "    species_df = data_top10[data_top10[\"scientific_name\"] == species]\n",
    "    hourly_counts = species_df.groupby(\"hour\")[\"filename\"].count()\n",
    "\n",
    "    plt.figure(figsize=(12,6))\n",
    "    sns.lineplot(x=hourly_counts.index, y=hourly_counts.values, marker=\"o\")\n",
    "    plt.title(f\"Number of Bird Recordings by Hour of Day — {species}\")\n",
    "    plt.xlabel(\"Hour of Day\")\n",
    "    plt.ylabel(\"Recording Count\")\n",
    "    plt.xticks(range(0,24))\n",
    "    plt.grid(True, linestyle=\"--\", alpha=0.6)\n",
    "    plt.show()"
   ],
   "id": "e5be61bca2d49bac",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "activity_matrix = data_top10.groupby([\"scientific_name\", \"hour\"])[\"filename\"].count().unstack(fill_value=0)\n",
    "\n",
    "plt.figure(figsize=(14, 8))\n",
    "sns.heatmap(activity_matrix, cmap=\"RdPu\")\n",
    "plt.title(\"Bird Activity Heatmap: Species vs Hour of Day\")\n",
    "plt.xlabel(\"Hour of Day\")\n",
    "plt.ylabel(\"Species (scientific_name)\")\n",
    "plt.show()"
   ],
   "id": "798e8c72c04c328b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import IsolationForest\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# columns to use for anomalies\n",
    "# weather_cols = [\n",
    "#     \"tempAve\",\"humidityAvg\",\"pressureMax\",\"windspeedAvg\",\n",
    "#     \"windgustHigh\",\"solarRadiationHigh\"\n",
    "# ]\n",
    "weather_cols =[\"tempAve\", \"pressureMax\", \"windgustHigh\", \"solarRadiationHigh\"]\n",
    "# ensure datetime -> hour exists\n",
    "data_top10[\"hour\"] = pd.to_datetime(data_top10[\"datetime\"], errors=\"coerce\").dt.hour\n",
    "\n",
    "for species in data_top10[\"scientific_name\"].unique():\n",
    "    df_species = data_top10[data_top10[\"scientific_name\"] == species].copy()\n",
    "\n",
    "    # skip tiny classes (IsolationForest needs some data)\n",
    "    if len(df_species) < 20:\n",
    "        print(f\"Skipping {species}: not enough samples ({len(df_species)})\")\n",
    "        continue\n",
    "\n",
    "    # --- Clean & scale on THIS species only ---\n",
    "    X = df_species[weather_cols].copy()\n",
    "    # fill NaNs with species means to avoid dropping rows\n",
    "    X = X.fillna(X.mean(numeric_only=True))\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    # --- Fit & predict anomalies for this species ---\n",
    "    iso = IsolationForest(contamination=0.05, random_state=42)\n",
    "    df_species[\"anomaly\"] = iso.fit_predict(X_scaled)   # -1 anomaly, 1 normal\n",
    "\n",
    "    print(f\"{species} anomaly counts:\\n{df_species['anomaly'].value_counts()}\\n\")\n",
    "\n",
    "    # map to labels for nicer legend\n",
    "    df_species[\"anomaly_label\"] = np.where(df_species[\"anomaly\"] == -1, \"Anomaly\", \"Normal\")\n",
    "\n",
    "    # --- Anomalies by hour (fill missing hours with 0 for readability) ---\n",
    "    hourly_anomalies = (\n",
    "        df_species.groupby(\"hour\")[\"anomaly\"]\n",
    "        .apply(lambda x: (x == -1).sum())\n",
    "        .reindex(range(24), fill_value=0)               # ensure 0–23 present\n",
    "        .reset_index(name=\"anomaly_count\")\n",
    "    )\n",
    "\n",
    "    plt.figure(figsize=(10,6))\n",
    "    sns.barplot(data=hourly_anomalies, x=\"hour\", y=\"anomaly_count\", color=\"red\")\n",
    "    plt.title(f\"Anomalies by Hour for {species}\")\n",
    "    plt.xlabel(\"Hour of Day\")\n",
    "    plt.ylabel(\"Number of Anomalies\")\n",
    "    plt.show()\n",
    "\n",
    "    # --- Visualize anomaly vs normal in weather space ---\n",
    "    plt.figure(figsize=(8,6))\n",
    "    sns.scatterplot(\n",
    "        data=df_species,\n",
    "        x=\"tempAve\", y=\"humidityAvg\",\n",
    "        hue=\"anomaly_label\", alpha=0.7\n",
    "    )\n",
    "    plt.title(f\"Weather Anomalies for {species}\")\n",
    "    plt.xlabel(\"Temperature (°C)\")\n",
    "    plt.ylabel(\"Humidity (%)\")\n",
    "    plt.legend(title=\"Status\")\n",
    "    plt.show()\n",
    "features_to_plot = [\"tempAve\", \"humidityAvg\", \"pressureMax\", \"solarRadiationHigh\", \"windspeedAvg\"]\n",
    "sns.pairplot(\n",
    "    df_species,\n",
    "    vars=features_to_plot,\n",
    "    hue=\"anomaly\",\n",
    "    plot_kws={\"alpha\": 0.6, \"s\": 30}\n",
    ")\n",
    "plt.suptitle(f\"Pairwise Weather Anomalies for {species}\", y=1.02)\n",
    "plt.show()\n"
   ],
   "id": "de48f85b19312cf5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "normal = df_species[df_species[\"anomaly\"] == 1]\n",
    "anomalous = df_species[df_species[\"anomaly\"] == -1]\n",
    "\n",
    "# Compare mean values per weather variable\n",
    "feature_diff = anomalous[weather_cols].mean() - normal[weather_cols].mean()\n",
    "feature_diff = feature_diff.sort_values(ascending=False)\n",
    "\n",
    "print(\"Average difference (anomaly - normal):\")\n",
    "print(feature_diff)\n",
    "feature_diff.plot(kind=\"barh\", figsize=(8,5), title=f\"Weather Feature Shift for Anomalies — {species}\")\n",
    "plt.xlabel(\"Mean difference (Anomaly - Normal)\")\n",
    "plt.show()"
   ],
   "id": "c1bd6b13e74f1902",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(\"\\033[91mtemperature data\\033[0m\")\n",
    "createBoxplotsOnData(data_top10,'scientific_name','tempAve','Distribution of Average Temperature per Scientific Name (Top 10)',\"Average Temperature (°C)\",'boxPlot_tempavg')\n",
    "createDistPlotsOnData(data_top10,'scientific_name','tempAve','Temperature Density per Scientific Name (with Counts)',\"Average Temperature (°C)\",\"distPlot_tempAvg\")\n",
    "\n",
    "print(\"\\033[91mwind speed data\\033[0m\")\n",
    "createBoxplotsOnData(data_top10,'scientific_name','windspeedAvg','Distribution of Average Wind Speed per Scientific Name (Top 10)',\"Average Temperature (°C)\",'boxPlot_windspeedAvg')\n",
    "createDistPlotsOnData(data_top10,'scientific_name','windspeedAvg','Temperature Density per Scientific Name (with Counts)',\"Average Wind Speed\",\"distPlot_windspeedAvg\")\n",
    "\n",
    "print(\"\\033[91mhumidity data\\033[0m\")\n",
    "createBoxplotsOnData(data_top10,'scientific_name','humidityAvg','Distribution of Average Wind Speed per Scientific Name (Top 10)',\"Average Humidity\",'boxPlot_humidityAvg')\n",
    "createDistPlotsOnData(data_top10,'scientific_name','humidityAvg','Temperature Density per Scientific Name (with Counts)',\"Average Humidity\",\"distPlot_humidityAvg\")\n"
   ],
   "id": "f3280218b67a18b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import re\n",
    "# Choose only relevant columns\n",
    "cols = ['dewptAvg','windgustHigh','windspeedAvg','tempAve', 'humidityAvg']\n",
    "\n",
    "# keep only numeric weather cols (safe)\n",
    "weather_cols = [c for c in cols if pd.api.types.is_numeric_dtype(data_top10[c])]\n",
    "\n",
    "for sp, sub in data_top10.dropna(subset=weather_cols+[species_col]).groupby(species_col):\n",
    "    # g = sns.pairplot(\n",
    "    #     sub[weather_cols],\n",
    "    #     diag_kind=\"kde\",     # or \"hist\"\n",
    "    #     kind=\"scatter\",      # or \"reg\"\n",
    "    #     corner=True,         # set False for the full square\n",
    "    #     plot_kws={\"s\": 12, \"alpha\": 0.6}\n",
    "    # )\n",
    "    # g.fig.suptitle(f\"Scatter Plot Matrix — {sp} (n={len(sub)})\", y=1.02)\n",
    "    g = sns.pairplot(\n",
    "    sub[cols],                # or df[cols + ['scientific_name']] with hue below\n",
    "    #hue='scientific_name', # add if you want colors by species\n",
    "    diag_kind='kde',         # or 'hist'\n",
    "    kind='scatter',          # or 'reg' for trend lines\n",
    "    plot_kws={'s':18, 'alpha':0.6}\n",
    "    )\n",
    "    g.fig.suptitle(\"Scatter Plot Matrix \", y=1.02)\n",
    "    safe = re.sub(r\"[^A-Za-z0-9_-]+\",\"_\", sp)\n",
    "    g.savefig(f\"{BASE_DIR}/Plots/pair-plot-{safe}\", dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    plt.close(g.fig)"
   ],
   "id": "824df0a1af7a44d4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Bird Activity vs Weather and Time",
   "id": "92c6ed49a8b2f6ff"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Idea: LLM To help with analysis",
   "id": "517ce78d94f292ed"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
